{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集和测试集的数据\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[(train.GrLivArea>4000)&(train.SalePrice<300000)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[(train.TotalBsmtSF>3000)&(train.SalePrice<300000)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接训练集和测试集数据，并删除Id,SalePrice\n",
    "full = pd.concat([train,test],ignore_index=True)\n",
    "full.drop(['Id','SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['LotFrontage'] = np.sqrt(full['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\",\"FireplaceQu\"]\n",
    "for col in cols:\n",
    "    full[col].fillna('None',inplace=True)\n",
    "\n",
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    full[col].fillna('None',inplace=True)\n",
    "\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    full[col].fillna(0,inplace=True)\n",
    "    \n",
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    full[col].fillna(0,inplace=True)\n",
    "    \n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    full[col].fillna('None',inplace=True)\n",
    "\n",
    "full[\"MasVnrType\"].fillna(\"None\",inplace=True)\n",
    "full[\"MasVnrArea\"].fillna(0,inplace=True)\n",
    "full['MSZoning'].fillna(full['MSZoning'].mode()[0],inplace=True)\n",
    "full.drop(['Utilities'], axis=1,inplace=True)\n",
    "full[\"Functional\"].fillna(\"Typ\",inplace=True)\n",
    "full['Electrical'].fillna(full['Electrical'].mode()[0],inplace=True)\n",
    "full['KitchenQual'].fillna(full['KitchenQual'].mode()[0],inplace=True)\n",
    "full['Exterior1st'].fillna(full['Exterior1st'].mode()[0],inplace=True)\n",
    "full['Exterior2nd'].fillna(full['Exterior2nd'].mode()[0],inplace=True)\n",
    "full['SaleType'].fillna(full['SaleType'].mode()[0],inplace=True)\n",
    "full['MSSubClass'].fillna(\"None\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['YearBuilt'] = LabelEncoder().fit_transform(full.YearBuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加新的特征，与SalePrice有较高的关系\n",
    "full['TotalSF'] = full['TotalBsmtSF'] + full['1stFlrSF'] +full['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['YrBltAndRemod'] = full['YearBuilt'] + full['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Total_sqr_footage'] = full['BsmtFinSF1']+full['BsmtFinSF2']+full['1stFlrSF']+full['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Total_Bathrooms'] = full['FullBath'] + full['BsmtFullBath'] + 0.5*full['HalfBath'] + 0.5*full['BsmtHalfBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.get_dummies(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = RobustScaler().fit_transform(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train)\n",
    "train_x = full[:train_len]\n",
    "test_x = full[train_len:]\n",
    "y = np.log(train.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model,X,y,scoring='neg_mean_squared_error',cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model):\n",
    "    pred = model.predict(train_x)\n",
    "    rmse = np.sqrt(mean_squared_error(y,pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet,SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10,shuffle=True,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.e-04, 3.e-04, 5.e-04, 9.e-04, 1.e-02, 3.e-02, 5.e-02, 9.e-02,\n",
       "       1.e-01, 3.e-01, 9.e-01, 1.e+00, 3.e+00, 5.e+00, 7.e+00, 9.e+00,\n",
       "       1.e+01, 2.e+01, 3.e+01, 4.e+01, 6.e+01, 7.e+01, 8.e+01, 9.e+01]),\n",
       "        cv=KFold(n_splits=10, random_state=123, shuffle=True),\n",
       "        fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
       "        store_cv_values=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [0.0001,0.0003,0.0005, 0.0009,\n",
    "          0.01,0.03,0.05, 0.09,\n",
    "          0.1,0.3,0.9,\n",
    "          1,3,5,7,9,\n",
    "          10,20,30,40,60,70,80,90]\n",
    "rcv = RidgeCV(alphas=alphas,cv=kfolds)\n",
    "rcv.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0980596610917399"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(rcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas2 = [0.00005,0.0001,0.0002,0.0005,0.0006,0.0007,0.0008,0.0009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcv = LassoCV(alphas=alphas2, random_state=123,cv=10).fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09923536068418425"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(lcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "elastic_cv = make_pipeline( \n",
    "                           ElasticNetCV( alphas=e_alphas, \n",
    "                                        cv=kfolds, l1_ratio=e_l1ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model3=elastic_cv.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10098244195069919"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(elastic_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "\n",
    "xg_reg=xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1.7817, missing=None, n_estimators=2200, n_jobs=1,\n",
       "             nthread=-1, objective='reg:linear', random_state=7,\n",
       "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
       "             silent=1, subsample=0.5213)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07799424675530847"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(xg_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
       "                          max_features='sqrt', max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=15, min_samples_split=10,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
       "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
       "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05043606374001577"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(C=20,epsilon=0.008,gamma=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=0.008, gamma=0.003,\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036080260234947766"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       #min_data_in_leaf=2,\n",
    "                                       #min_sum_hessian_in_leaf=11\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.75, bagging_freq=5, bagging_seed=7,\n",
       "              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              feature_fraction=0.2, feature_fraction_seed=7,\n",
       "              importance_type='split', learning_rate=0.01, max_bin=200,\n",
       "              max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=5000, n_jobs=-1, num_leaves=4,\n",
       "              objective='regression', random_state=None, reg_alpha=0.0,\n",
       "              reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0, verbose=-1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07530241932834864"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "linsvr = LinearSVR()\n",
    "sgd = SGDRegressor(max_iter=1000,tol=1e-3)\n",
    "ker = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "extra = ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "                    max_features='auto', max_leaf_nodes=None,\n",
       "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                    min_samples_leaf=1, min_samples_split=2,\n",
       "                    min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                    oob_score=False, random_state=None, verbose=0,\n",
       "                    warm_start=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_x,y)\n",
    "linsvr.fit(train_x,y)\n",
    "sgd.fit(train_x,y)\n",
    "ker.fit(train_x,y)\n",
    "extra.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(rcv,lcv,gbr,svr,rf,linsvr,sgd,ker,extra,xg_reg,lightgbm),\n",
    "                               meta_regressor=lcv,\n",
    "                               use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingCVRegressor(cv=5,\n",
       "                    meta_regressor=LassoCV(alphas=[5e-05, 0.0001, 0.0002,\n",
       "                                                   0.0005, 0.0006, 0.0007,\n",
       "                                                   0.0008, 0.0009],\n",
       "                                           copy_X=True, cv=10, eps=0.001,\n",
       "                                           fit_intercept=True, max_iter=1000,\n",
       "                                           n_alphas=100, n_jobs=None,\n",
       "                                           normalize=False, positive=False,\n",
       "                                           precompute='auto', random_state=123,\n",
       "                                           selection='cyclic', tol=0.0001,\n",
       "                                           verbose=False),\n",
       "                    n_jobs=None, pre_dispatch='2*n_jobs', rando...\n",
       "                                              max_depth=-1,\n",
       "                                              min_child_samples=20,\n",
       "                                              min_child_weight=0.001,\n",
       "                                              min_split_gain=0.0,\n",
       "                                              n_estimators=5000, n_jobs=-1,\n",
       "                                              num_leaves=4,\n",
       "                                              objective='regression',\n",
       "                                              random_state=None, reg_alpha=0.0,\n",
       "                                              reg_lambda=0.0, silent=True,\n",
       "                                              subsample=1.0,\n",
       "                                              subsample_for_bin=200000,\n",
       "                                              subsample_freq=0, verbose=-1)),\n",
       "                    shuffle=True, store_train_meta_features=False,\n",
       "                    use_features_in_secondary=True, verbose=0)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_gen.fit(train_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08599336807687888"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(stack_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(y,y_pred):\n",
    "    print(np.sqrt(mean_squared_error(y,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 0.1*stack_gen.predict(test_x)+\\\n",
    "       0.1*lightgbm.predict(test_x)+\\\n",
    "       0.1*xg_reg.predict(test_x)+\\\n",
    "       0.4*svr.predict(test_x)+\\\n",
    "       0.3*gbr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.exp(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Id':test.Id,'SalePrice':pred})\n",
    "result.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
