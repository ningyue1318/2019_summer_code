{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vgg_Fish_Classification",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzQNP9RCcLPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZP_FFaQcWH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle',exist_ok = True)\n",
        "!cp /content/gdrive/My\\ Drive/DeepLearning/kaggle/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc3cIZXMcl69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c the-nature-conservancy-fisheries-monitoring"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hBC5DYScnsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d ningyue1/vgg-weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0jCWc8DiHYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 解压预训练权重\n",
        "! unzip /content/vgg-weight.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK8Kyxq_iTUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 解压训练集数据\n",
        "! unzip /content/train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wAnwnHxiXRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 解压第一部分测试集数据\n",
        "!unzip /content/test_stg1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmWJ6D6ViZOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 解压第二部分测试集数据\n",
        "!7za x test_stg2.7z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEiLJsPKibd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os,cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_tKHiKTiqc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义取图片的路径\n",
        "TRAIN_DIR = '/content/train/'\n",
        "TEST_DIR = '/content/test_stg2/'\n",
        "WEIGHT_DIR = '/content/vgg16_weights.npz'\n",
        "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8_2Lg00isf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获取图片的路径方法\n",
        "def get_images(data_dir,fish):\n",
        "    \"\"\"Load files from train folder\"\"\"\n",
        "    fish_dir = data_dir+'{}'.format(fish)\n",
        "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
        "    return images\n",
        "# 将图片读入内存\n",
        "def read_image(src):\n",
        "    \"\"\"Read and resize individual images\"\"\"\n",
        "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
        "    im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FAAYX62ivFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获取训练数据\n",
        "files = []\n",
        "y_all = []\n",
        "\n",
        "for fish in FISH_CLASSES:\n",
        "    fish_files = get_images(TRAIN_DIR,fish)\n",
        "    files.extend(fish_files)\n",
        "    \n",
        "    y_fish = np.tile(fish, len(fish_files))\n",
        "    y_all.extend(y_fish)\n",
        "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
        "    \n",
        "y_all = np.array(y_all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RduCuI4ixef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将所有图片加载到内存中\n",
        "X = np.ndarray((len(files), 224, 224, 3))\n",
        "\n",
        "for i, im in enumerate(files): \n",
        "    X[i] = read_image(TRAIN_DIR+im)\n",
        "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upA1Cab3i0O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 转化为one-hot编码\n",
        "y = LabelEncoder().fit_transform(y_all)\n",
        "y = np_utils.to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhSB-Hxi3Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
        "                                                    test_size=0.2, random_state=23, \n",
        "                                                    stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqBgOayqi3uO",
        "colab_type": "code",
        "outputId": "fbf26030-e11e-4830-dc9c-e3b4efe5163b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape,X_valid.shape,y_train.shape,y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3021, 224, 224, 3) (756, 224, 224, 3) (3021, 8) (756, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i55elsEUi-Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 加载预训练的权重\n",
        "pre_weight = np.load(WEIGHT_DIR,allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmpVxllxi_nh",
        "colab_type": "code",
        "outputId": "fc0f5cb3-6cbc-4672-aa29-6b44ca594b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "list(pre_weight.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conv4_3_W',\n",
              " 'conv5_1_b',\n",
              " 'conv1_2_b',\n",
              " 'conv5_2_b',\n",
              " 'conv1_1_W',\n",
              " 'conv5_3_b',\n",
              " 'conv5_2_W',\n",
              " 'conv5_3_W',\n",
              " 'conv1_1_b',\n",
              " 'fc7_b',\n",
              " 'conv5_1_W',\n",
              " 'conv1_2_W',\n",
              " 'conv3_2_W',\n",
              " 'conv4_2_b',\n",
              " 'conv4_1_b',\n",
              " 'conv3_3_W',\n",
              " 'conv2_1_b',\n",
              " 'conv3_1_b',\n",
              " 'conv2_2_W',\n",
              " 'fc6_b',\n",
              " 'fc8_b',\n",
              " 'conv4_3_b',\n",
              " 'conv2_2_b',\n",
              " 'fc6_W',\n",
              " 'fc8_W',\n",
              " 'fc7_W',\n",
              " 'conv3_2_b',\n",
              " 'conv4_2_W',\n",
              " 'conv3_3_b',\n",
              " 'conv3_1_W',\n",
              " 'conv2_1_W',\n",
              " 'conv4_1_W']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrzPmX-b6x-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学习参数\n",
        "learning_rate = 0.003\n",
        "num_epochs = 75\n",
        "batch_size = 64\n",
        "batch_num = 47\n",
        "\n",
        "# 网络参数\n",
        "dropout_rate = 0.5\n",
        "num_classes = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC9pd5kk68GY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建模型\n",
        "x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
        "y = tf.placeholder(tf.int32, [None, num_classes])\n",
        "\n",
        "W_conv = {\n",
        "    'conv1_1': tf.Variable(pre_weight['conv1_1_W'],trainable=False),\n",
        "    'conv1_2': tf.Variable(pre_weight['conv1_2_W'],trainable=False),\n",
        "    'conv2_1': tf.Variable(pre_weight['conv2_1_W'],trainable=False),\n",
        "    'conv2_2': tf.Variable(pre_weight['conv2_2_W'],trainable=False),\n",
        "    'conv3_1': tf.Variable(pre_weight['conv3_1_W'],trainable=False),\n",
        "    'conv3_2': tf.Variable(pre_weight['conv3_2_W'],trainable=False),\n",
        "    'conv3_3': tf.Variable(pre_weight['conv3_3_W'],trainable=False),\n",
        "    'conv4_1': tf.Variable(pre_weight['conv4_1_W'],trainable=False),\n",
        "    'conv4_2': tf.Variable(pre_weight['conv4_2_W'],trainable=False),\n",
        "    'conv4_3': tf.Variable(pre_weight['conv4_3_W'],trainable=False),\n",
        "    'conv5_1': tf.Variable(pre_weight['conv5_1_W'],trainable=False),\n",
        "    'conv5_2': tf.Variable(pre_weight['conv5_2_W'],trainable=False),\n",
        "    'conv5_3': tf.Variable(pre_weight['conv5_3_W'],trainable=False),\n",
        "    'fc6': tf.Variable(tf.truncated_normal([7*7*512, 4096],stddev=0.001)),\n",
        "    'fc7': tf.Variable(tf.truncated_normal([4096, 4096], stddev=0.001)),\n",
        "    'fc8': tf.Variable(tf.truncated_normal([4096, num_classes], stddev=0.001))\n",
        "}\n",
        "b_conv = {\n",
        "    'conv1_1': tf.Variable(pre_weight['conv1_1_b'],trainable=False),\n",
        "    'conv1_2': tf.Variable(pre_weight['conv1_2_b'],trainable=False),\n",
        "    'conv2_1': tf.Variable(pre_weight['conv2_1_b'],trainable=False),\n",
        "    'conv2_2': tf.Variable(pre_weight['conv2_2_b'],trainable=False),\n",
        "    'conv3_1': tf.Variable(pre_weight['conv3_1_b'],trainable=False),\n",
        "    'conv3_2': tf.Variable(pre_weight['conv3_2_b'],trainable=False),\n",
        "    'conv3_3': tf.Variable(pre_weight['conv3_3_b'],trainable=False),\n",
        "    'conv4_1': tf.Variable(pre_weight['conv4_1_b'],trainable=False),\n",
        "    'conv4_2': tf.Variable(pre_weight['conv4_2_b'],trainable=False),\n",
        "    'conv4_3': tf.Variable(pre_weight['conv4_3_b'],trainable=False),\n",
        "    'conv5_1': tf.Variable(pre_weight['conv5_1_b'],trainable=False),\n",
        "    'conv5_2': tf.Variable(pre_weight['conv5_2_b'],trainable=False),\n",
        "    'conv5_3': tf.Variable(pre_weight['conv5_3_b'],trainable=False),\n",
        "    'fc6': tf.Variable(tf.constant(0.1,dtype=tf.float32, shape=[4096])),\n",
        "    'fc7': tf.Variable(tf.constant(0.1,dtype=tf.float32, shape=[4096])),\n",
        "    'fc8': tf.Variable(tf.constant(0.1,dtype=tf.float32, shape=[num_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2uSwRT49vS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 第一层\n",
        "conv1_1 = tf.nn.conv2d(x,W_conv['conv1_1'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv1_1 = tf.nn.bias_add(conv1_1,b_conv['conv1_1'])\n",
        "conv1_1 = tf.nn.relu(conv1_1)\n",
        "conv1_2 = tf.nn.conv2d(conv1_1,W_conv['conv1_2'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv1_2 = tf.nn.bias_add(conv1_2,b_conv['conv1_2'])\n",
        "conv1_2 = tf.nn.relu(conv1_2)\n",
        "pool1 = tf.nn.max_pool(conv1_2, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
        "\n",
        "# 第二层\n",
        "conv2_1 = tf.nn.conv2d(pool1,W_conv['conv2_1'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv2_1 = tf.nn.bias_add(conv2_1,b_conv['conv2_1'])\n",
        "conv2_1 = tf.nn.relu(conv2_1)\n",
        "conv2_2 = tf.nn.conv2d(conv2_1,W_conv['conv2_2'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv2_2 = tf.nn.bias_add(conv2_2,b_conv['conv2_2'])\n",
        "conv2_2 = tf.nn.relu(conv2_2)\n",
        "pool2 = tf.nn.max_pool(conv2_2, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
        "\n",
        "# 第三层\n",
        "conv3_1 = tf.nn.conv2d(pool2,W_conv['conv3_1'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv3_1 = tf.nn.bias_add(conv3_1,b_conv['conv3_1'])\n",
        "conv3_1 = tf.nn.relu(conv3_1)\n",
        "conv3_2 = tf.nn.conv2d(conv3_1,W_conv['conv3_2'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv3_2 = tf.nn.bias_add(conv3_2,b_conv['conv3_2'])\n",
        "conv3_2 = tf.nn.relu(conv3_2)\n",
        "conv3_3 = tf.nn.conv2d(conv3_2,W_conv['conv3_3'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv3_3 = tf.nn.bias_add(conv3_3,b_conv['conv3_3'])\n",
        "conv3_3 = tf.nn.relu(conv3_3)\n",
        "pool3 = tf.nn.max_pool(conv3_3, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
        "\n",
        "# 第四层\n",
        "conv4_1 = tf.nn.conv2d(pool3,W_conv['conv4_1'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv4_1 = tf.nn.bias_add(conv4_1,b_conv['conv4_1'])\n",
        "conv4_1 = tf.nn.relu(conv4_1)\n",
        "conv4_2 = tf.nn.conv2d(conv4_1,W_conv['conv4_2'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv4_2 = tf.nn.bias_add(conv4_2,b_conv['conv4_2'])\n",
        "conv4_2 = tf.nn.relu(conv4_2)\n",
        "conv4_3 = tf.nn.conv2d(conv4_2,W_conv['conv4_3'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv4_3 = tf.nn.bias_add(conv4_3,b_conv['conv4_3'])\n",
        "conv4_3 = tf.nn.relu(conv4_3)\n",
        "pool4 = tf.nn.max_pool(conv4_3, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
        "\n",
        "# 第五层\n",
        "conv5_1 = tf.nn.conv2d(pool4,W_conv['conv5_1'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv5_1 = tf.nn.bias_add(conv5_1,b_conv['conv5_1'])\n",
        "conv5_1 = tf.nn.relu(conv5_1)\n",
        "conv5_2 = tf.nn.conv2d(conv5_1,W_conv['conv5_2'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv5_2 = tf.nn.bias_add(conv5_2,b_conv['conv5_2'])\n",
        "conv5_2 = tf.nn.relu(conv5_2)\n",
        "conv5_3 = tf.nn.conv2d(conv5_2,W_conv['conv5_3'],strides=[1, 1, 1, 1], padding = 'SAME')\n",
        "conv5_3 = tf.nn.bias_add(conv5_3,b_conv['conv5_3'])\n",
        "conv5_3 = tf.nn.relu(conv5_3)\n",
        "pool5 = tf.nn.max_pool(conv5_3, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"VALID\")\n",
        "\n",
        "reshape = tf.reshape(pool5, [-1, 7*7*512])\n",
        "\n",
        "fc6 = tf.add(tf.matmul(reshape, W_conv['fc6']), b_conv['fc6'])\n",
        "fc6 = tf.nn.relu(fc6)\n",
        "fc6 = tf.nn.dropout(fc6,0.5)\n",
        "\n",
        "fc7 = tf.add(tf.matmul(fc6, W_conv['fc7']), b_conv['fc7'])\n",
        "fc7 = tf.nn.relu(fc7)\n",
        "fc7 = tf.nn.dropout(fc7,0.5)\n",
        "\n",
        "fc8 = tf.add(tf.matmul(fc7, W_conv['fc8']), b_conv['fc8'])\n",
        "fc8 = tf.nn.relu(fc8)\n",
        "fc8 = tf.nn.dropout(fc8,0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guw-OkTHa7-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义损失\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=fc8, labels=y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "# 评估模型\n",
        "correct_pred = tf.equal(tf.argmax(fc8, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VepkS4IgTqe",
        "colab_type": "code",
        "outputId": "cfd4903e-f017-4641-87b7-c25cb10aed99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(num_epochs):\n",
        "        for j in range(batch_num):\n",
        "            X_train_data = X_train[j*batch_size:(j+1)*batch_size,:,:,:]\n",
        "            y_train_data = y_train[j*batch_size:(j+1)*batch_size,:]\n",
        "            sess.run(optimizer,feed_dict={x:X_train_data,y:y_train_data})\n",
        "            if j % 10 ==0:  \n",
        "                _loss = sess.run(loss, feed_dict={x:X_train_data,y:y_train_data})\n",
        "                train_accuracy = sess.run(accuracy, feed_dict={x:X_train_data, y: y_train_data})\n",
        "                print('Epoch: {:>2} Batch {:>5} Loss: {:>10.6f} Accuracy: {:.6f}'.format(i, j, _loss, train_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 Batch     0 Loss:   2.047429 Accuracy: 0.328125\n",
            "Epoch:  0 Batch    10 Loss:   1.872801 Accuracy: 0.343750\n",
            "Epoch:  0 Batch    20 Loss:   1.795046 Accuracy: 0.421875\n",
            "Epoch:  0 Batch    30 Loss:   1.969324 Accuracy: 0.328125\n",
            "Epoch:  0 Batch    40 Loss:   1.853640 Accuracy: 0.328125\n",
            "Epoch:  1 Batch     0 Loss:   1.797387 Accuracy: 0.375000\n",
            "Epoch:  1 Batch    10 Loss:   1.824742 Accuracy: 0.390625\n",
            "Epoch:  1 Batch    20 Loss:   1.736486 Accuracy: 0.375000\n",
            "Epoch:  1 Batch    30 Loss:   1.834299 Accuracy: 0.359375\n",
            "Epoch:  1 Batch    40 Loss:   1.737167 Accuracy: 0.421875\n",
            "Epoch:  2 Batch     0 Loss:   1.727727 Accuracy: 0.421875\n",
            "Epoch:  2 Batch    10 Loss:   1.672629 Accuracy: 0.437500\n",
            "Epoch:  2 Batch    20 Loss:   1.530337 Accuracy: 0.343750\n",
            "Epoch:  2 Batch    30 Loss:   1.834884 Accuracy: 0.296875\n",
            "Epoch:  2 Batch    40 Loss:   1.818706 Accuracy: 0.437500\n",
            "Epoch:  3 Batch     0 Loss:   1.484197 Accuracy: 0.437500\n",
            "Epoch:  3 Batch    10 Loss:   1.560740 Accuracy: 0.468750\n",
            "Epoch:  3 Batch    20 Loss:   1.603918 Accuracy: 0.437500\n",
            "Epoch:  3 Batch    30 Loss:   1.656526 Accuracy: 0.515625\n",
            "Epoch:  3 Batch    40 Loss:   1.478764 Accuracy: 0.515625\n",
            "Epoch:  4 Batch     0 Loss:   1.524002 Accuracy: 0.500000\n",
            "Epoch:  4 Batch    10 Loss:   1.569571 Accuracy: 0.593750\n",
            "Epoch:  4 Batch    20 Loss:   1.431326 Accuracy: 0.609375\n",
            "Epoch:  4 Batch    30 Loss:   1.677120 Accuracy: 0.421875\n",
            "Epoch:  4 Batch    40 Loss:   1.381605 Accuracy: 0.531250\n",
            "Epoch:  5 Batch     0 Loss:   1.485230 Accuracy: 0.640625\n",
            "Epoch:  5 Batch    10 Loss:   1.552639 Accuracy: 0.562500\n",
            "Epoch:  5 Batch    20 Loss:   1.386095 Accuracy: 0.656250\n",
            "Epoch:  5 Batch    30 Loss:   1.380274 Accuracy: 0.500000\n",
            "Epoch:  5 Batch    40 Loss:   1.417592 Accuracy: 0.546875\n",
            "Epoch:  6 Batch     0 Loss:   1.256011 Accuracy: 0.515625\n",
            "Epoch:  6 Batch    10 Loss:   1.316110 Accuracy: 0.546875\n",
            "Epoch:  6 Batch    20 Loss:   1.576952 Accuracy: 0.640625\n",
            "Epoch:  6 Batch    30 Loss:   1.356342 Accuracy: 0.484375\n",
            "Epoch:  6 Batch    40 Loss:   1.439751 Accuracy: 0.515625\n",
            "Epoch:  7 Batch     0 Loss:   1.339855 Accuracy: 0.593750\n",
            "Epoch:  7 Batch    10 Loss:   1.410810 Accuracy: 0.609375\n",
            "Epoch:  7 Batch    20 Loss:   1.436891 Accuracy: 0.609375\n",
            "Epoch:  7 Batch    30 Loss:   1.550039 Accuracy: 0.593750\n",
            "Epoch:  7 Batch    40 Loss:   1.199622 Accuracy: 0.671875\n",
            "Epoch:  8 Batch     0 Loss:   1.284236 Accuracy: 0.703125\n",
            "Epoch:  8 Batch    10 Loss:   1.121024 Accuracy: 0.671875\n",
            "Epoch:  8 Batch    20 Loss:   1.570069 Accuracy: 0.734375\n",
            "Epoch:  8 Batch    30 Loss:   1.454380 Accuracy: 0.625000\n",
            "Epoch:  8 Batch    40 Loss:   1.499430 Accuracy: 0.781250\n",
            "Epoch:  9 Batch     0 Loss:   1.279052 Accuracy: 0.671875\n",
            "Epoch:  9 Batch    10 Loss:   1.428043 Accuracy: 0.625000\n",
            "Epoch:  9 Batch    20 Loss:   1.520168 Accuracy: 0.750000\n",
            "Epoch:  9 Batch    30 Loss:   1.237025 Accuracy: 0.671875\n",
            "Epoch:  9 Batch    40 Loss:   1.431722 Accuracy: 0.734375\n",
            "Epoch: 10 Batch     0 Loss:   1.169966 Accuracy: 0.656250\n",
            "Epoch: 10 Batch    10 Loss:   1.133629 Accuracy: 0.656250\n",
            "Epoch: 10 Batch    20 Loss:   1.109785 Accuracy: 0.734375\n",
            "Epoch: 10 Batch    30 Loss:   1.211444 Accuracy: 0.656250\n",
            "Epoch: 10 Batch    40 Loss:   1.202527 Accuracy: 0.718750\n",
            "Epoch: 11 Batch     0 Loss:   1.254838 Accuracy: 0.640625\n",
            "Epoch: 11 Batch    10 Loss:   1.300835 Accuracy: 0.656250\n",
            "Epoch: 11 Batch    20 Loss:   1.243211 Accuracy: 0.750000\n",
            "Epoch: 11 Batch    30 Loss:   1.233118 Accuracy: 0.687500\n",
            "Epoch: 11 Batch    40 Loss:   1.160740 Accuracy: 0.671875\n",
            "Epoch: 12 Batch     0 Loss:   1.221145 Accuracy: 0.718750\n",
            "Epoch: 12 Batch    10 Loss:   1.199806 Accuracy: 0.687500\n",
            "Epoch: 12 Batch    20 Loss:   1.052904 Accuracy: 0.703125\n",
            "Epoch: 12 Batch    30 Loss:   1.204860 Accuracy: 0.656250\n",
            "Epoch: 12 Batch    40 Loss:   1.082365 Accuracy: 0.718750\n",
            "Epoch: 13 Batch     0 Loss:   0.919873 Accuracy: 0.796875\n",
            "Epoch: 13 Batch    10 Loss:   1.233456 Accuracy: 0.671875\n",
            "Epoch: 13 Batch    20 Loss:   0.997736 Accuracy: 0.687500\n",
            "Epoch: 13 Batch    30 Loss:   1.452894 Accuracy: 0.640625\n",
            "Epoch: 13 Batch    40 Loss:   1.443104 Accuracy: 0.734375\n",
            "Epoch: 14 Batch     0 Loss:   1.225882 Accuracy: 0.718750\n",
            "Epoch: 14 Batch    10 Loss:   1.042870 Accuracy: 0.656250\n",
            "Epoch: 14 Batch    20 Loss:   1.145270 Accuracy: 0.796875\n",
            "Epoch: 14 Batch    30 Loss:   1.187867 Accuracy: 0.609375\n",
            "Epoch: 14 Batch    40 Loss:   1.105991 Accuracy: 0.734375\n",
            "Epoch: 15 Batch     0 Loss:   1.252421 Accuracy: 0.718750\n",
            "Epoch: 15 Batch    10 Loss:   1.192282 Accuracy: 0.640625\n",
            "Epoch: 15 Batch    20 Loss:   1.216263 Accuracy: 0.703125\n",
            "Epoch: 15 Batch    30 Loss:   1.168542 Accuracy: 0.609375\n",
            "Epoch: 15 Batch    40 Loss:   0.909569 Accuracy: 0.765625\n",
            "Epoch: 16 Batch     0 Loss:   1.089762 Accuracy: 0.718750\n",
            "Epoch: 16 Batch    10 Loss:   1.180492 Accuracy: 0.703125\n",
            "Epoch: 16 Batch    20 Loss:   1.028867 Accuracy: 0.671875\n",
            "Epoch: 16 Batch    30 Loss:   0.996672 Accuracy: 0.640625\n",
            "Epoch: 16 Batch    40 Loss:   0.735485 Accuracy: 0.703125\n",
            "Epoch: 17 Batch     0 Loss:   1.032081 Accuracy: 0.687500\n",
            "Epoch: 17 Batch    10 Loss:   1.167160 Accuracy: 0.687500\n",
            "Epoch: 17 Batch    20 Loss:   1.400676 Accuracy: 0.734375\n",
            "Epoch: 17 Batch    30 Loss:   1.188047 Accuracy: 0.687500\n",
            "Epoch: 17 Batch    40 Loss:   1.156790 Accuracy: 0.734375\n",
            "Epoch: 18 Batch     0 Loss:   1.402264 Accuracy: 0.687500\n",
            "Epoch: 18 Batch    10 Loss:   1.027378 Accuracy: 0.656250\n",
            "Epoch: 18 Batch    20 Loss:   1.298406 Accuracy: 0.781250\n",
            "Epoch: 18 Batch    30 Loss:   1.053717 Accuracy: 0.640625\n",
            "Epoch: 18 Batch    40 Loss:   1.052439 Accuracy: 0.750000\n",
            "Epoch: 19 Batch     0 Loss:   1.174743 Accuracy: 0.750000\n",
            "Epoch: 19 Batch    10 Loss:   1.149955 Accuracy: 0.656250\n",
            "Epoch: 19 Batch    20 Loss:   1.323550 Accuracy: 0.671875\n",
            "Epoch: 19 Batch    30 Loss:   1.309624 Accuracy: 0.734375\n",
            "Epoch: 19 Batch    40 Loss:   1.052282 Accuracy: 0.750000\n",
            "Epoch: 20 Batch     0 Loss:   1.041209 Accuracy: 0.671875\n",
            "Epoch: 20 Batch    10 Loss:   1.112537 Accuracy: 0.671875\n",
            "Epoch: 20 Batch    20 Loss:   1.213862 Accuracy: 0.734375\n",
            "Epoch: 20 Batch    30 Loss:   1.070346 Accuracy: 0.750000\n",
            "Epoch: 20 Batch    40 Loss:   0.954530 Accuracy: 0.734375\n",
            "Epoch: 21 Batch     0 Loss:   1.181569 Accuracy: 0.718750\n",
            "Epoch: 21 Batch    10 Loss:   1.303097 Accuracy: 0.687500\n",
            "Epoch: 21 Batch    20 Loss:   0.983901 Accuracy: 0.765625\n",
            "Epoch: 21 Batch    30 Loss:   0.981797 Accuracy: 0.640625\n",
            "Epoch: 21 Batch    40 Loss:   1.086417 Accuracy: 0.718750\n",
            "Epoch: 22 Batch     0 Loss:   1.220175 Accuracy: 0.718750\n",
            "Epoch: 22 Batch    10 Loss:   1.173566 Accuracy: 0.687500\n",
            "Epoch: 22 Batch    20 Loss:   1.130162 Accuracy: 0.765625\n",
            "Epoch: 22 Batch    30 Loss:   1.341122 Accuracy: 0.750000\n",
            "Epoch: 22 Batch    40 Loss:   1.158443 Accuracy: 0.765625\n",
            "Epoch: 23 Batch     0 Loss:   1.180063 Accuracy: 0.640625\n",
            "Epoch: 23 Batch    10 Loss:   1.269633 Accuracy: 0.671875\n",
            "Epoch: 23 Batch    20 Loss:   1.101025 Accuracy: 0.703125\n",
            "Epoch: 23 Batch    30 Loss:   1.303420 Accuracy: 0.593750\n",
            "Epoch: 23 Batch    40 Loss:   0.919574 Accuracy: 0.734375\n",
            "Epoch: 24 Batch     0 Loss:   1.172434 Accuracy: 0.718750\n",
            "Epoch: 24 Batch    10 Loss:   1.173049 Accuracy: 0.656250\n",
            "Epoch: 24 Batch    20 Loss:   1.108783 Accuracy: 0.734375\n",
            "Epoch: 24 Batch    30 Loss:   1.205344 Accuracy: 0.671875\n",
            "Epoch: 24 Batch    40 Loss:   1.082256 Accuracy: 0.734375\n",
            "Epoch: 25 Batch     0 Loss:   1.334262 Accuracy: 0.734375\n",
            "Epoch: 25 Batch    10 Loss:   1.336977 Accuracy: 0.656250\n",
            "Epoch: 25 Batch    20 Loss:   1.372175 Accuracy: 0.796875\n",
            "Epoch: 25 Batch    30 Loss:   1.144503 Accuracy: 0.718750\n",
            "Epoch: 25 Batch    40 Loss:   1.178282 Accuracy: 0.703125\n",
            "Epoch: 26 Batch     0 Loss:   1.082760 Accuracy: 0.687500\n",
            "Epoch: 26 Batch    10 Loss:   1.207102 Accuracy: 0.703125\n",
            "Epoch: 26 Batch    20 Loss:   1.173670 Accuracy: 0.703125\n",
            "Epoch: 26 Batch    30 Loss:   1.304843 Accuracy: 0.734375\n",
            "Epoch: 26 Batch    40 Loss:   1.106348 Accuracy: 0.796875\n",
            "Epoch: 27 Batch     0 Loss:   0.914654 Accuracy: 0.625000\n",
            "Epoch: 27 Batch    10 Loss:   1.433749 Accuracy: 0.609375\n",
            "Epoch: 27 Batch    20 Loss:   1.043705 Accuracy: 0.796875\n",
            "Epoch: 27 Batch    30 Loss:   1.081444 Accuracy: 0.640625\n",
            "Epoch: 27 Batch    40 Loss:   1.176486 Accuracy: 0.734375\n",
            "Epoch: 28 Batch     0 Loss:   1.044868 Accuracy: 0.640625\n",
            "Epoch: 28 Batch    10 Loss:   1.138978 Accuracy: 0.687500\n",
            "Epoch: 28 Batch    20 Loss:   1.107584 Accuracy: 0.750000\n",
            "Epoch: 28 Batch    30 Loss:   1.204913 Accuracy: 0.671875\n",
            "Epoch: 28 Batch    40 Loss:   1.101569 Accuracy: 0.828125\n",
            "Epoch: 29 Batch     0 Loss:   1.075036 Accuracy: 0.750000\n",
            "Epoch: 29 Batch    10 Loss:   1.171658 Accuracy: 0.640625\n",
            "Epoch: 29 Batch    20 Loss:   1.365995 Accuracy: 0.765625\n",
            "Epoch: 29 Batch    30 Loss:   1.366426 Accuracy: 0.625000\n",
            "Epoch: 29 Batch    40 Loss:   1.045201 Accuracy: 0.750000\n",
            "Epoch: 30 Batch     0 Loss:   1.334221 Accuracy: 0.734375\n",
            "Epoch: 30 Batch    10 Loss:   1.174474 Accuracy: 0.687500\n",
            "Epoch: 30 Batch    20 Loss:   1.268283 Accuracy: 0.734375\n",
            "Epoch: 30 Batch    30 Loss:   1.271098 Accuracy: 0.671875\n",
            "Epoch: 30 Batch    40 Loss:   1.043496 Accuracy: 0.750000\n",
            "Epoch: 31 Batch     0 Loss:   1.171005 Accuracy: 0.718750\n",
            "Epoch: 31 Batch    10 Loss:   1.239473 Accuracy: 0.656250\n",
            "Epoch: 31 Batch    20 Loss:   1.300544 Accuracy: 0.765625\n",
            "Epoch: 31 Batch    30 Loss:   1.239394 Accuracy: 0.625000\n",
            "Epoch: 31 Batch    40 Loss:   1.204628 Accuracy: 0.750000\n",
            "Epoch: 32 Batch     0 Loss:   1.085386 Accuracy: 0.765625\n",
            "Epoch: 32 Batch    10 Loss:   1.238278 Accuracy: 0.609375\n",
            "Epoch: 32 Batch    20 Loss:   0.879188 Accuracy: 0.781250\n",
            "Epoch: 32 Batch    30 Loss:   1.268268 Accuracy: 0.703125\n",
            "Epoch: 32 Batch    40 Loss:   1.107845 Accuracy: 0.734375\n",
            "Epoch: 33 Batch     0 Loss:   1.141932 Accuracy: 0.687500\n",
            "Epoch: 33 Batch    10 Loss:   1.271791 Accuracy: 0.703125\n",
            "Epoch: 33 Batch    20 Loss:   1.074233 Accuracy: 0.718750\n",
            "Epoch: 33 Batch    30 Loss:   1.304065 Accuracy: 0.687500\n",
            "Epoch: 33 Batch    40 Loss:   1.237471 Accuracy: 0.687500\n",
            "Epoch: 34 Batch     0 Loss:   0.979742 Accuracy: 0.671875\n",
            "Epoch: 34 Batch    10 Loss:   1.334716 Accuracy: 0.734375\n",
            "Epoch: 34 Batch    20 Loss:   1.237210 Accuracy: 0.703125\n",
            "Epoch: 34 Batch    30 Loss:   1.334563 Accuracy: 0.625000\n",
            "Epoch: 34 Batch    40 Loss:   0.880817 Accuracy: 0.750000\n",
            "Epoch: 35 Batch     0 Loss:   1.105945 Accuracy: 0.687500\n",
            "Epoch: 35 Batch    10 Loss:   1.300804 Accuracy: 0.718750\n",
            "Epoch: 35 Batch    20 Loss:   1.300110 Accuracy: 0.750000\n",
            "Epoch: 35 Batch    30 Loss:   1.300474 Accuracy: 0.656250\n",
            "Epoch: 35 Batch    40 Loss:   1.076511 Accuracy: 0.765625\n",
            "Epoch: 36 Batch     0 Loss:   1.365715 Accuracy: 0.671875\n",
            "Epoch: 36 Batch    10 Loss:   1.106826 Accuracy: 0.703125\n",
            "Epoch: 36 Batch    20 Loss:   0.915681 Accuracy: 0.812500\n",
            "Epoch: 36 Batch    30 Loss:   1.139443 Accuracy: 0.671875\n",
            "Epoch: 36 Batch    40 Loss:   1.173860 Accuracy: 0.718750\n",
            "Epoch: 37 Batch     0 Loss:   1.203474 Accuracy: 0.718750\n",
            "Epoch: 37 Batch    10 Loss:   1.205342 Accuracy: 0.687500\n",
            "Epoch: 37 Batch    20 Loss:   1.015021 Accuracy: 0.781250\n",
            "Epoch: 37 Batch    30 Loss:   1.105654 Accuracy: 0.656250\n",
            "Epoch: 37 Batch    40 Loss:   1.303769 Accuracy: 0.734375\n",
            "Epoch: 38 Batch     0 Loss:   1.041420 Accuracy: 0.750000\n",
            "Epoch: 38 Batch    10 Loss:   1.171218 Accuracy: 0.609375\n",
            "Epoch: 38 Batch    20 Loss:   1.073882 Accuracy: 0.734375\n",
            "Epoch: 38 Batch    30 Loss:   1.236669 Accuracy: 0.703125\n",
            "Epoch: 38 Batch    40 Loss:   0.883439 Accuracy: 0.750000\n",
            "Epoch: 39 Batch     0 Loss:   0.943874 Accuracy: 0.703125\n",
            "Epoch: 39 Batch    10 Loss:   1.139579 Accuracy: 0.687500\n",
            "Epoch: 39 Batch    20 Loss:   1.141171 Accuracy: 0.765625\n",
            "Epoch: 39 Batch    30 Loss:   1.170694 Accuracy: 0.718750\n",
            "Epoch: 39 Batch    40 Loss:   1.016337 Accuracy: 0.687500\n",
            "Epoch: 40 Batch     0 Loss:   1.073220 Accuracy: 0.671875\n",
            "Epoch: 40 Batch    10 Loss:   1.074042 Accuracy: 0.734375\n",
            "Epoch: 40 Batch    20 Loss:   1.270150 Accuracy: 0.796875\n",
            "Epoch: 40 Batch    30 Loss:   1.205041 Accuracy: 0.718750\n",
            "Epoch: 40 Batch    40 Loss:   0.751050 Accuracy: 0.703125\n",
            "Epoch: 41 Batch     0 Loss:   1.267687 Accuracy: 0.703125\n",
            "Epoch: 41 Batch    10 Loss:   1.074893 Accuracy: 0.625000\n",
            "Epoch: 41 Batch    20 Loss:   0.814591 Accuracy: 0.781250\n",
            "Epoch: 41 Batch    30 Loss:   1.236350 Accuracy: 0.656250\n",
            "Epoch: 41 Batch    40 Loss:   1.106955 Accuracy: 0.703125\n",
            "Epoch: 42 Batch     0 Loss:   1.300811 Accuracy: 0.796875\n",
            "Epoch: 42 Batch    10 Loss:   1.141304 Accuracy: 0.687500\n",
            "Epoch: 42 Batch    20 Loss:   1.235538 Accuracy: 0.750000\n",
            "Epoch: 42 Batch    30 Loss:   1.138783 Accuracy: 0.687500\n",
            "Epoch: 42 Batch    40 Loss:   1.268831 Accuracy: 0.796875\n",
            "Epoch: 43 Batch     0 Loss:   1.269542 Accuracy: 0.734375\n",
            "Epoch: 43 Batch    10 Loss:   1.042729 Accuracy: 0.609375\n",
            "Epoch: 43 Batch    20 Loss:   0.943323 Accuracy: 0.796875\n",
            "Epoch: 43 Batch    30 Loss:   1.041330 Accuracy: 0.703125\n",
            "Epoch: 43 Batch    40 Loss:   1.235859 Accuracy: 0.765625\n",
            "Epoch: 44 Batch     0 Loss:   1.333601 Accuracy: 0.781250\n",
            "Epoch: 44 Batch    10 Loss:   1.171209 Accuracy: 0.718750\n",
            "Epoch: 44 Batch    20 Loss:   1.042589 Accuracy: 0.765625\n",
            "Epoch: 44 Batch    30 Loss:   1.106306 Accuracy: 0.656250\n",
            "Epoch: 44 Batch    40 Loss:   1.073187 Accuracy: 0.687500\n",
            "Epoch: 45 Batch     0 Loss:   1.040583 Accuracy: 0.671875\n",
            "Epoch: 45 Batch    10 Loss:   1.008095 Accuracy: 0.640625\n",
            "Epoch: 45 Batch    20 Loss:   1.041616 Accuracy: 0.765625\n",
            "Epoch: 45 Batch    30 Loss:   1.170683 Accuracy: 0.703125\n",
            "Epoch: 45 Batch    40 Loss:   0.977416 Accuracy: 0.703125\n",
            "Epoch: 46 Batch     0 Loss:   1.235699 Accuracy: 0.750000\n",
            "Epoch: 46 Batch    10 Loss:   1.170777 Accuracy: 0.640625\n",
            "Epoch: 46 Batch    20 Loss:   0.911065 Accuracy: 0.781250\n",
            "Epoch: 46 Batch    30 Loss:   1.235701 Accuracy: 0.718750\n",
            "Epoch: 46 Batch    40 Loss:   1.077906 Accuracy: 0.765625\n",
            "Epoch: 47 Batch     0 Loss:   1.073863 Accuracy: 0.703125\n",
            "Epoch: 47 Batch    10 Loss:   1.009344 Accuracy: 0.625000\n",
            "Epoch: 47 Batch    20 Loss:   1.139265 Accuracy: 0.796875\n",
            "Epoch: 47 Batch    30 Loss:   1.332799 Accuracy: 0.703125\n",
            "Epoch: 47 Batch    40 Loss:   0.944569 Accuracy: 0.781250\n",
            "Epoch: 48 Batch     0 Loss:   1.170907 Accuracy: 0.703125\n",
            "Epoch: 48 Batch    10 Loss:   1.170853 Accuracy: 0.656250\n",
            "Epoch: 48 Batch    20 Loss:   1.170545 Accuracy: 0.781250\n",
            "Epoch: 48 Batch    30 Loss:   1.202725 Accuracy: 0.578125\n",
            "Epoch: 48 Batch    40 Loss:   1.431176 Accuracy: 0.718750\n",
            "Epoch: 49 Batch     0 Loss:   1.072999 Accuracy: 0.625000\n",
            "Epoch: 49 Batch    10 Loss:   1.300317 Accuracy: 0.671875\n",
            "Epoch: 49 Batch    20 Loss:   1.177018 Accuracy: 0.765625\n",
            "Epoch: 49 Batch    30 Loss:   1.204018 Accuracy: 0.703125\n",
            "Epoch: 49 Batch    40 Loss:   0.977891 Accuracy: 0.765625\n",
            "Epoch: 50 Batch     0 Loss:   1.105216 Accuracy: 0.781250\n",
            "Epoch: 50 Batch    10 Loss:   1.203666 Accuracy: 0.656250\n",
            "Epoch: 50 Batch    20 Loss:   1.105559 Accuracy: 0.796875\n",
            "Epoch: 50 Batch    30 Loss:   1.172421 Accuracy: 0.671875\n",
            "Epoch: 50 Batch    40 Loss:   1.105462 Accuracy: 0.750000\n",
            "Epoch: 51 Batch     0 Loss:   1.333788 Accuracy: 0.703125\n",
            "Epoch: 51 Batch    10 Loss:   1.300117 Accuracy: 0.703125\n",
            "Epoch: 51 Batch    20 Loss:   1.332934 Accuracy: 0.812500\n",
            "Epoch: 51 Batch    30 Loss:   1.074321 Accuracy: 0.609375\n",
            "Epoch: 51 Batch    40 Loss:   1.267551 Accuracy: 0.718750\n",
            "Epoch: 52 Batch     0 Loss:   1.204694 Accuracy: 0.640625\n",
            "Epoch: 52 Batch    10 Loss:   1.267551 Accuracy: 0.703125\n",
            "Epoch: 52 Batch    20 Loss:   1.171893 Accuracy: 0.765625\n",
            "Epoch: 52 Batch    30 Loss:   1.170292 Accuracy: 0.734375\n",
            "Epoch: 52 Batch    40 Loss:   0.911041 Accuracy: 0.796875\n",
            "Epoch: 53 Batch     0 Loss:   1.170280 Accuracy: 0.718750\n",
            "Epoch: 53 Batch    10 Loss:   0.943238 Accuracy: 0.750000\n",
            "Epoch: 53 Batch    20 Loss:   1.109038 Accuracy: 0.781250\n",
            "Epoch: 53 Batch    30 Loss:   1.172020 Accuracy: 0.640625\n",
            "Epoch: 53 Batch    40 Loss:   0.975772 Accuracy: 0.671875\n",
            "Epoch: 54 Batch     0 Loss:   1.238274 Accuracy: 0.703125\n",
            "Epoch: 54 Batch    10 Loss:   1.007924 Accuracy: 0.718750\n",
            "Epoch: 54 Batch    20 Loss:   1.073777 Accuracy: 0.750000\n",
            "Epoch: 54 Batch    30 Loss:   1.237844 Accuracy: 0.687500\n",
            "Epoch: 54 Batch    40 Loss:   1.007615 Accuracy: 0.750000\n",
            "Epoch: 55 Batch     0 Loss:   1.236593 Accuracy: 0.656250\n",
            "Epoch: 55 Batch    10 Loss:   1.170598 Accuracy: 0.703125\n",
            "Epoch: 55 Batch    20 Loss:   1.202635 Accuracy: 0.750000\n",
            "Epoch: 55 Batch    30 Loss:   1.268306 Accuracy: 0.703125\n",
            "Epoch: 55 Batch    40 Loss:   1.008205 Accuracy: 0.703125\n",
            "Epoch: 56 Batch     0 Loss:   1.235010 Accuracy: 0.734375\n",
            "Epoch: 56 Batch    10 Loss:   1.235415 Accuracy: 0.718750\n",
            "Epoch: 56 Batch    20 Loss:   1.008423 Accuracy: 0.765625\n",
            "Epoch: 56 Batch    30 Loss:   1.072883 Accuracy: 0.625000\n",
            "Epoch: 56 Batch    40 Loss:   0.911341 Accuracy: 0.765625\n",
            "Epoch: 57 Batch     0 Loss:   1.300899 Accuracy: 0.703125\n",
            "Epoch: 57 Batch    10 Loss:   1.300506 Accuracy: 0.687500\n",
            "Epoch: 57 Batch    20 Loss:   1.234925 Accuracy: 0.734375\n",
            "Epoch: 57 Batch    30 Loss:   1.040859 Accuracy: 0.718750\n",
            "Epoch: 57 Batch    40 Loss:   1.040533 Accuracy: 0.781250\n",
            "Epoch: 58 Batch     0 Loss:   1.202582 Accuracy: 0.718750\n",
            "Epoch: 58 Batch    10 Loss:   1.170968 Accuracy: 0.718750\n",
            "Epoch: 58 Batch    20 Loss:   1.040905 Accuracy: 0.875000\n",
            "Epoch: 58 Batch    30 Loss:   1.336043 Accuracy: 0.625000\n",
            "Epoch: 58 Batch    40 Loss:   1.268033 Accuracy: 0.718750\n",
            "Epoch: 59 Batch     0 Loss:   1.202637 Accuracy: 0.750000\n",
            "Epoch: 59 Batch    10 Loss:   1.236518 Accuracy: 0.640625\n",
            "Epoch: 59 Batch    20 Loss:   1.105575 Accuracy: 0.765625\n",
            "Epoch: 59 Batch    30 Loss:   1.236699 Accuracy: 0.640625\n",
            "Epoch: 59 Batch    40 Loss:   1.105167 Accuracy: 0.812500\n",
            "Epoch: 60 Batch     0 Loss:   1.073251 Accuracy: 0.640625\n",
            "Epoch: 60 Batch    10 Loss:   1.207153 Accuracy: 0.750000\n",
            "Epoch: 60 Batch    20 Loss:   1.137789 Accuracy: 0.750000\n",
            "Epoch: 60 Batch    30 Loss:   1.008245 Accuracy: 0.687500\n",
            "Epoch: 60 Batch    40 Loss:   1.105201 Accuracy: 0.656250\n",
            "Epoch: 61 Batch     0 Loss:   1.105117 Accuracy: 0.718750\n",
            "Epoch: 61 Batch    10 Loss:   1.234964 Accuracy: 0.687500\n",
            "Epoch: 61 Batch    20 Loss:   1.267515 Accuracy: 0.750000\n",
            "Epoch: 61 Batch    30 Loss:   1.137736 Accuracy: 0.625000\n",
            "Epoch: 61 Batch    40 Loss:   1.269235 Accuracy: 0.734375\n",
            "Epoch: 62 Batch     0 Loss:   1.268891 Accuracy: 0.656250\n",
            "Epoch: 62 Batch    10 Loss:   1.301419 Accuracy: 0.625000\n",
            "Epoch: 62 Batch    20 Loss:   1.235226 Accuracy: 0.765625\n",
            "Epoch: 62 Batch    30 Loss:   0.911073 Accuracy: 0.718750\n",
            "Epoch: 62 Batch    40 Loss:   1.170229 Accuracy: 0.687500\n",
            "Epoch: 63 Batch     0 Loss:   1.203342 Accuracy: 0.687500\n",
            "Epoch: 63 Batch    10 Loss:   1.137347 Accuracy: 0.671875\n",
            "Epoch: 63 Batch    20 Loss:   1.073318 Accuracy: 0.781250\n",
            "Epoch: 63 Batch    30 Loss:   1.333093 Accuracy: 0.625000\n",
            "Epoch: 63 Batch    40 Loss:   1.236807 Accuracy: 0.781250\n",
            "Epoch: 64 Batch     0 Loss:   1.040332 Accuracy: 0.718750\n",
            "Epoch: 64 Batch    10 Loss:   1.104997 Accuracy: 0.625000\n",
            "Epoch: 64 Batch    20 Loss:   1.202516 Accuracy: 0.734375\n",
            "Epoch: 64 Batch    30 Loss:   1.237510 Accuracy: 0.671875\n",
            "Epoch: 64 Batch    40 Loss:   1.041309 Accuracy: 0.828125\n",
            "Epoch: 65 Batch     0 Loss:   1.267594 Accuracy: 0.750000\n",
            "Epoch: 65 Batch    10 Loss:   1.105481 Accuracy: 0.562500\n",
            "Epoch: 65 Batch    20 Loss:   1.104913 Accuracy: 0.750000\n",
            "Epoch: 65 Batch    30 Loss:   0.975792 Accuracy: 0.671875\n",
            "Epoch: 65 Batch    40 Loss:   0.878372 Accuracy: 0.703125\n",
            "Epoch: 66 Batch     0 Loss:   1.267644 Accuracy: 0.718750\n",
            "Epoch: 66 Batch    10 Loss:   1.267925 Accuracy: 0.671875\n",
            "Epoch: 66 Batch    20 Loss:   1.137823 Accuracy: 0.750000\n",
            "Epoch: 66 Batch    30 Loss:   1.105176 Accuracy: 0.640625\n",
            "Epoch: 66 Batch    40 Loss:   1.105314 Accuracy: 0.796875\n",
            "Epoch: 67 Batch     0 Loss:   1.105211 Accuracy: 0.734375\n",
            "Epoch: 67 Batch    10 Loss:   1.137634 Accuracy: 0.656250\n",
            "Epoch: 67 Batch    20 Loss:   0.845517 Accuracy: 0.765625\n",
            "Epoch: 67 Batch    30 Loss:   1.299870 Accuracy: 0.671875\n",
            "Epoch: 67 Batch    40 Loss:   1.202627 Accuracy: 0.687500\n",
            "Epoch: 68 Batch     0 Loss:   1.042264 Accuracy: 0.718750\n",
            "Epoch: 68 Batch    10 Loss:   1.072595 Accuracy: 0.671875\n",
            "Epoch: 68 Batch    20 Loss:   1.235645 Accuracy: 0.765625\n",
            "Epoch: 68 Batch    30 Loss:   0.976387 Accuracy: 0.640625\n",
            "Epoch: 68 Batch    40 Loss:   1.137861 Accuracy: 0.781250\n",
            "Epoch: 69 Batch     0 Loss:   1.137657 Accuracy: 0.687500\n",
            "Epoch: 69 Batch    10 Loss:   1.332287 Accuracy: 0.656250\n",
            "Epoch: 69 Batch    20 Loss:   0.942912 Accuracy: 0.781250\n",
            "Epoch: 69 Batch    30 Loss:   1.465041 Accuracy: 0.671875\n",
            "Epoch: 69 Batch    40 Loss:   1.105392 Accuracy: 0.765625\n",
            "Epoch: 70 Batch     0 Loss:   1.203165 Accuracy: 0.718750\n",
            "Epoch: 70 Batch    10 Loss:   1.169878 Accuracy: 0.687500\n",
            "Epoch: 70 Batch    20 Loss:   1.007977 Accuracy: 0.718750\n",
            "Epoch: 70 Batch    30 Loss:   1.073627 Accuracy: 0.656250\n",
            "Epoch: 70 Batch    40 Loss:   0.910365 Accuracy: 0.687500\n",
            "Epoch: 71 Batch     0 Loss:   1.267432 Accuracy: 0.734375\n",
            "Epoch: 71 Batch    10 Loss:   1.332311 Accuracy: 0.671875\n",
            "Epoch: 71 Batch    20 Loss:   0.978476 Accuracy: 0.781250\n",
            "Epoch: 71 Batch    30 Loss:   1.072724 Accuracy: 0.687500\n",
            "Epoch: 71 Batch    40 Loss:   1.011840 Accuracy: 0.781250\n",
            "Epoch: 72 Batch     0 Loss:   1.202563 Accuracy: 0.656250\n",
            "Epoch: 72 Batch    10 Loss:   1.236539 Accuracy: 0.671875\n",
            "Epoch: 72 Batch    20 Loss:   1.170308 Accuracy: 0.750000\n",
            "Epoch: 72 Batch    30 Loss:   1.170360 Accuracy: 0.640625\n",
            "Epoch: 72 Batch    40 Loss:   0.817346 Accuracy: 0.828125\n",
            "Epoch: 73 Batch     0 Loss:   1.105259 Accuracy: 0.656250\n",
            "Epoch: 73 Batch    10 Loss:   1.169981 Accuracy: 0.671875\n",
            "Epoch: 73 Batch    20 Loss:   0.975600 Accuracy: 0.765625\n",
            "Epoch: 73 Batch    30 Loss:   1.300406 Accuracy: 0.718750\n",
            "Epoch: 73 Batch    40 Loss:   1.073362 Accuracy: 0.765625\n",
            "Epoch: 74 Batch     0 Loss:   1.202638 Accuracy: 0.734375\n",
            "Epoch: 74 Batch    10 Loss:   1.007501 Accuracy: 0.718750\n",
            "Epoch: 74 Batch    20 Loss:   1.235093 Accuracy: 0.812500\n",
            "Epoch: 74 Batch    30 Loss:   1.267640 Accuracy: 0.625000\n",
            "Epoch: 74 Batch    40 Loss:   1.108214 Accuracy: 0.765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV7D-LFHgWrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "del X\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TaRly_xga5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " test_file_path = [TEST_DIR+im for im in os.listdir(TEST_DIR)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG8qPHvggdZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = np.zeros((12153,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itMrGCu3ggDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = np.ndarray((100, 224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmcqEQTJggwe",
        "colab_type": "code",
        "outputId": "f4ea0b14-fd0b-4d46-b215-9b689ba28a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(121):\n",
        "      print(i)\n",
        "      for j in range(100):\n",
        "        test[j] = read_image(test_file_path[i*100+j])\n",
        "      t_pred = sess.run(tf.nn.softmax(fc8),feed_dict={x:test})\n",
        "      test_preds[i*100:(i+1)*100,:] = t_pred\n",
        "    for i in range(53):\n",
        "      test[j] = read_image(test_file_path[121*100+i])\n",
        "    t_pred = sess.run(tf.nn.softmax(fc8),feed_dict={x:test[0:53]})\n",
        "    test_preds[121*100:121*100+53,:] = t_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-FQVLN3giv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file_path1 = ['test_stg2/'+im for im in os.listdir(TEST_DIR)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bVaOp1RgkWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
        "submission.insert(0, 'image', test_file_path1)\n",
        "submission.head()\n",
        "\n",
        "\n",
        "submission.to_csv('submisision2.csv',index=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuFUeFVmgnAL",
        "colab_type": "code",
        "outputId": "5dc52e91-e7ac-40c9-f201-6a05a6ea8f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>ALB</th>\n",
              "      <th>BET</th>\n",
              "      <th>DOL</th>\n",
              "      <th>LAG</th>\n",
              "      <th>NoF</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>SHARK</th>\n",
              "      <th>YFT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_stg2/image_05356.jpg</td>\n",
              "      <td>0.118372</td>\n",
              "      <td>0.118372</td>\n",
              "      <td>0.143498</td>\n",
              "      <td>0.118372</td>\n",
              "      <td>0.146273</td>\n",
              "      <td>0.118372</td>\n",
              "      <td>0.118372</td>\n",
              "      <td>0.118372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_stg2/image_03402.jpg</td>\n",
              "      <td>0.117797</td>\n",
              "      <td>0.117797</td>\n",
              "      <td>0.148447</td>\n",
              "      <td>0.117797</td>\n",
              "      <td>0.117797</td>\n",
              "      <td>0.117797</td>\n",
              "      <td>0.144773</td>\n",
              "      <td>0.117797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_stg2/image_06302.jpg</td>\n",
              "      <td>0.131480</td>\n",
              "      <td>0.138973</td>\n",
              "      <td>0.136623</td>\n",
              "      <td>0.134238</td>\n",
              "      <td>0.108405</td>\n",
              "      <td>0.133471</td>\n",
              "      <td>0.108405</td>\n",
              "      <td>0.108405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_stg2/image_03224.jpg</td>\n",
              "      <td>0.131143</td>\n",
              "      <td>0.131861</td>\n",
              "      <td>0.131238</td>\n",
              "      <td>0.127301</td>\n",
              "      <td>0.107340</td>\n",
              "      <td>0.107340</td>\n",
              "      <td>0.132859</td>\n",
              "      <td>0.130917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_stg2/image_07578.jpg</td>\n",
              "      <td>0.108042</td>\n",
              "      <td>0.128779</td>\n",
              "      <td>0.108042</td>\n",
              "      <td>0.134476</td>\n",
              "      <td>0.131037</td>\n",
              "      <td>0.131103</td>\n",
              "      <td>0.128885</td>\n",
              "      <td>0.129635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       image       ALB       BET  ...     OTHER     SHARK       YFT\n",
              "0  test_stg2/image_05356.jpg  0.118372  0.118372  ...  0.118372  0.118372  0.118372\n",
              "1  test_stg2/image_03402.jpg  0.117797  0.117797  ...  0.117797  0.144773  0.117797\n",
              "2  test_stg2/image_06302.jpg  0.131480  0.138973  ...  0.133471  0.108405  0.108405\n",
              "3  test_stg2/image_03224.jpg  0.131143  0.131861  ...  0.107340  0.132859  0.130917\n",
              "4  test_stg2/image_07578.jpg  0.108042  0.128779  ...  0.131103  0.128885  0.129635\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E19LQ0D_prX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_files = [im for im in os.listdir('/content/test_stg1')]\n",
        "test = np.ndarray((len(test_files), 224, 224, 3))\n",
        "for i, im in enumerate(test_files): \n",
        "    test[i] = read_image('/content/test_stg1/'+im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqZP_0W_qA-T",
        "colab_type": "code",
        "outputId": "e23b994d-60ed-4dfc-821b-4dc019db6102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "test_preds = np.zeros((1000,8))\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(10):\n",
        "        print(i)\n",
        "        t_pred = sess.run(tf.nn.softmax(fc8),feed_dict={x:test[i*100:(i+1)*100,:,:,:]})\n",
        "        test_preds[i*100:(i+1)*100,:] = t_pred\n",
        "\n",
        "\n",
        "\n",
        "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
        "submission.insert(0, 'image', test_files)\n",
        "submission.head()\n",
        "\n",
        "\n",
        "submission.to_csv('submisision1.csv',index=None)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}